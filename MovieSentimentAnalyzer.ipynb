{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0T1hucsMLsd"
      },
      "source": [
        "Movie Sentiment Analyzer by Timothy Gunn <br> July 5th, 2025 <br>\n",
        "This code extracts movie sentiment data provided in .tar format and creates an MLP using that data to predict whether a given movie review has an overall positive or negative sentiment. To train the model, users can download the data provided by Stanford at https://ai.stanford.edu/~amaas/data/sentiment/ . At the end, an extra cell of code is provided so the user can input their own review into the model and test it out themselves.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_lMw_SSgqQw"
      },
      "outputs": [],
      "source": [
        "#Uploading the file (a .tar) that contains the data\n",
        "from google.colab import files\n",
        "sentiments = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqo_IA7csuE2"
      },
      "outputs": [],
      "source": [
        "#Extracting the data from the .tar file\n",
        "import tarfile\n",
        "\n",
        "filename = \"aclImdb_v1.tar\"\n",
        "\n",
        "with tarfile.open(filename, \"r\") as tar:\n",
        "    tar.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzXSiP5MyI9B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#Loads data from a given path and creates a list of text, label (1 or 0 for positive and negative respectivley) pairs\n",
        "def load_reviews(path, label):\n",
        "  data = []\n",
        "  for fname in os.listdir(path):\n",
        "    if fname.endswith(\".txt\"):\n",
        "      with open(os.path.join(path, fname), encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "        data.append((text,label))\n",
        "  return data\n",
        "\n",
        "#Loads 1000 positive reviews\n",
        "train_pos = load_reviews(\"aclImdb/train/pos\", 1)[:1000]\n",
        "\n",
        "#Loads 1000 negative reviews\n",
        "train_neg = load_reviews(\"aclImdb/train/neg\", 0)[:1000]\n",
        "\n",
        "#Combines the positive and negative reviews into one larger dataset\n",
        "data = train_pos + train_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blI_rkKnyl5I"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Creates individual lists for the review texts and the labels associates with them\n",
        "texts = [text for text, label in data]\n",
        "labels = [label for text, label in data]\n",
        "\n",
        "#Splitting the data into training and testing sets (stratifying based on the labels to ensure one set does not get a higher proportion of\n",
        "# positives or negatives)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(texts, labels, test_size=.2, random_state=42, stratify=labels)\n",
        "\n",
        "#Initialize tge TF-IDF vectorizer with a limit of 5000 features (words) and English stop words removed (like a, and, but, the)\n",
        "vectorizer = TfidfVectorizer(max_features=5000, stop_words = 'english')\n",
        "\n",
        "#Fit the vectorizer to the training text and transform it into a numerical feature vector\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train).toarray()\n",
        "\n",
        "#Transform the test text into a numerical feature vector (without refitting the vectorizer)\n",
        "X_test_vectorized = vectorizer.transform(X_test).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PlrgaVg3zAL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "#Convert vectorized training features into a Float Tensor\n",
        "X_train_tensor = torch.tensor(X_train_vectorized, dtype=torch.float32)\n",
        "\n",
        "#Convert vectorized training features into a Float Tensor and add a dimension (To make them column vectors for BCE)\n",
        "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "#Perform the same operations on the test data\n",
        "X_test_tensor = torch.tensor(X_test_vectorized, dtype=torch.float32)\n",
        "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "#Combine the features and labels into a PyTorch dataset object\n",
        "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
        "\n",
        "#Creates data loaders for both the training and testing sets which will shuffle data each epoch\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRFkh74O4-Ep"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "#Define an MLP class\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_size):\n",
        "    super(MLP, self).__init__()\n",
        "    #Defining the layers of the MLP (ReLU introduces non-linearity, Sigmoid for classification at the end)\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(input_size, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  #Ensures the neural network is feed-forward\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "#Creates an instance of the model\n",
        "model = MLP(input_size=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwQUxGXA73mn"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#Definie the loss function and optimizer to be used during training\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = .005)\n",
        "\n",
        "#Train the model using 5 epochs of data\n",
        "for epoch in range(5):\n",
        "  total_loss = 0\n",
        "  #Iterate through each mini batch in the data loader\n",
        "  for batch_x, batch_y in train_loader:\n",
        "    #Clear previous gradients\n",
        "    optimizer.zero_grad()\n",
        "    #Compute predicted outputs\n",
        "    outputs = model(batch_x)\n",
        "    #Calculate loss\n",
        "    loss = criterion(outputs, batch_y)\n",
        "    #Backpropagation\n",
        "    loss.backward()\n",
        "    #Gradient Descent\n",
        "    optimizer.step()\n",
        "    #Update loss\n",
        "    total_loss += loss.item()\n",
        "  print(f\"Epoch: {epoch+1}, Loss: {total_loss:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIDl90---VXd"
      },
      "outputs": [],
      "source": [
        "#Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "#Disable gradient tracking to save memory and speed up computatiom\n",
        "with torch.no_grad():\n",
        "  #Get predicted probabilities on the test set\n",
        "  predictions = model(X_test_tensor)\n",
        "  #Convert probabilities to binary class predictions\n",
        "  predicted_classes = (predictions >= .5).float()\n",
        "  #Compute model accuracy by comparing predicted labels to true labels and counting correct predictions\n",
        "  accuracy = (predicted_classes.eq(Y_test_tensor)).sum().item() / len(Y_test_tensor)\n",
        "  print(f\"Accuracy: {accuracy: }\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HTohNz_SJFZO"
      },
      "outputs": [],
      "source": [
        "def predicted_review_sentiment(review):\n",
        "  #Set model to evaluation mode\n",
        "  model.eval()\n",
        "  #Disable gradient tracking\n",
        "  with torch.no_grad():\n",
        "    #Vectorize the input text\n",
        "    vectorized = vectorizer.transform([review]).toarray()\n",
        "    #Convert to Float Tensor\n",
        "    input_tensor = torch.tensor(vectorized, dtype=torch.float32)\n",
        "    #Get model prediction\n",
        "    prediction = model(input_tensor)\n",
        "    #Convert probability to binary class prediction\n",
        "    predicted_class = (predictions >= .5).float().item()\n",
        "\n",
        "    if predicted_class == 1:\n",
        "      sentiment = 'Positive'\n",
        "    else:\n",
        "      sentiment = 'Negative'\n",
        "\n",
        "    print(f'Review: {review}\\n')\n",
        "    print(f'Prediceted Sentiment: {sentiment}\\n')\n",
        "\n",
        "\n",
        "user_input = input('Enter a movie review to be input into the model: ')\n",
        "predicted_review_sentiment(user_input)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
